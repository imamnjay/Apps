nn=sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1=c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new=lapply(list, `[[`, 1)
pp1=score=lapply(list, `[[`, 2)
nn1=score=lapply(list, `[[`, 3)
scores.df = data.frame(score=score_new, text=sentences)
positive.df = data.frame(Positive=pp1, text=sentences)
negative.df = data.frame(Negative=nn1, text=sentences)
list_df=list(scores.df, positive.df, negative.df)
return(list_df)
}
result = score.sentiment(coba_tweets, pos.words, neg.words)
#Creating a copy of result data frame
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Positive=table2$value, Negative=table3$value, Score=table1$value)
table_final$Summary <- ifelse(table_final$Score < 0, "Negative", ifelse(table_final$Score > 0, "Positive","Netral"))
#table_final$Summary <- ifelse(table_final$Score < 0, "Negative","Positive")
table_bersih = table_final[!table_final$Score == 0,]
positif = sum(table_final$Score > 0)
negatif = sum(table_final$Score < 0)
netral = sum(table_final$Score == 0)
#positive percen
PosPc = table_final$Positive
negPC = table_final$Negative
table_final$PosPercent = PosPc/ (PosPc+negPC)
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp
#negative percen
table_final$NegPercent = negPC/ (PosPc+negPC)
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn
View(table_final)
write.csv(table_final,'table_finalfix.csv', row.names = F)
datalexicon <- read.csv('table_finalfix.csv')
positif_or_negatif <- read.csv('table_finalfix.csv')
str(positif_or_negatif)
View(positif_or_negatif)
which(!complete.cases(positif_or_negatif))
table(positif_or_negatif$Summary)
prop.table(table(positif_or_negatif$Summary))
positif_or_negatif$Text <- as.character(positif_or_negatif$Text)
positif_or_negatif$Textlength <- nchar(positif_or_negatif$Text)
library("tm")
taaruf_corpus <- Corpus(VectorSource(positif_or_negatif$Text))
print(taaruf_corpus)
inspect(taaruf_corpus)
dtm_tweets <- DocumentTermMatrix(VCorpus(VectorSource(datalexicon$Text)))
inspect(dtm_tweets)
dtm_tweets_latih <- dtm_tweets[1:3587, ]
label_sentimen_latih <- datalexicon[1:3587, ]$Summary
konversi_jumlah <- function(x){
x <- ifelse(x > 0, "Ada", "TAda")
}
sentimen_latih <- apply(dtm_tweets_latih,
MARGIN = 2, konversi_jumlah)
library(e1071)
pengklas_sentimen <-naiveBayes(sentimen_latih, label_sentimen_latih)
pengklas_sentimen$apriori
pengklas_sentimen$tables[1]
prediksi_sentimen <- predict(pengklas_sentimen, sentimen_latih)
table(prediksi_sentimen)
#hasil dalam bentuk tabel
library(gmodels)
CrossTable(prediksi_sentimen, label_sentimen_latih,
prop.chisq = F,prop.t = F,
dnn = c('terprediksi' , 'manual'))
library(caret)
conf.mat <- confusionMatrix(prediksi_sentimen, label_sentimen_latih )
table(prediksi_sentimen)
conf.mat
dtm_tweets <- DocumentTermMatrix(VCorpus(VectorSource(datalexicon$Text)))
inspect(dtm_tweets)
dtm_tweets_uji <- dtm_tweets[3588:5123, ]
label_sentimen_uji <- datalexicon[3588:5123, ]$Summary
konversi_jumlah <- function(x){
x <- ifelse(x > 0, "Ada", "TAda")
}
sentimen_uji <- apply(dtm_tweets_uji,
MARGIN = 2, konversi_jumlah)
pengklas_sentimen <-naiveBayes(sentimen_uji, label_sentimen_uji)
pengklas_sentimen$apriori
pengklas_sentimen$tables[1]
prediksi_sentimen <- predict(pengklas_sentimen, sentimen_uji)
table(prediksi_sentimen)
CrossTable(prediksi_sentimen, label_sentimen_uji,
prop.chisq = F,prop.t = F,
dnn = c('terprediksi' , 'manual'))
conf.mat <- confusionMatrix(prediksi_sentimen, label_sentimen_uji )
table(prediksi_sentimen)
conf.mat
View('prediksi_sentimen')
View('table_finalfix.csv')
runApp()
runApp()
runApp()
pos.words = scan("positive.tsv", what='character', comment.char=';')
neg.words = scan("negative.tsv", what='character', comment.char=';')
coba_tweets <- read.csv('stemming.csv')
coba_tweets <- as.character(coba_tweets$x)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
require(plyr)
require(stringr)
require(katadasaR)
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)
sentence = gsub('\n','',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
words = sapply(words, katadasaR)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp=sum(pos.matches)
nn=sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1=c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new=lapply(list, `[[`, 1)
pp1=score=lapply(list, `[[`, 2)
nn1=score=lapply(list, `[[`, 3)
scores.df = data.frame(score=score_new, text=sentences)
positive.df = data.frame(Positive=pp1, text=sentences)
negative.df = data.frame(Negative=nn1, text=sentences)
list_df=list(scores.df, positive.df, negative.df)
return(list_df)
}
result = score.sentiment(coba_tweets, pos.words, neg.words)
#Creating a copy of result data frame
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Positive=table2$value, Negative=table3$value, Score=table1$value)
#table_final$Summary <- ifelse(table_final$Score < 0, "Negative", ifelse(table_final$Score > 0, "Positive","Netral"))
table_final$Summary <- ifelse(table_final$Score < 0, "Negative","Positive")
table_bersih = table_final[!table_final$Score == 0,]
positif = sum(table_final$Score > 0)
negatif = sum(table_final$Score < 0)
netral = sum(table_final$Score == 0)
#positive percen
PosPc = table_final$Positive
negPC = table_final$Negative
table_final$PosPercent = PosPc/ (PosPc+negPC)
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp
#negative percen
table_final$NegPercent = negPC/ (PosPc+negPC)
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn
View(table_final)
write.csv(table_final,'table_finalfix2.csv', row.names = F)
setwd("~/KUUUUUULIAAAHHHH/Skripsi/Program/sentimentaaruff/BARU")
#Klasifikasi Data dengan Naive Bayes Classifier
datalexicon <- read.csv('table_finalfix2.csv')
positif_or_negatif <- read.csv('table_finalfix2.csv')
str(positif_or_negatif)
View(positif_or_negatif)
which(!complete.cases(positif_or_negatif))
table(positif_or_negatif$Summary)
prop.table(table(positif_or_negatif$Summary))
positif_or_negatif$Text <- as.character(positif_or_negatif$Text)
positif_or_negatif$Textlength <- nchar(positif_or_negatif$Text)
library("tm")
taaruf_corpus <- Corpus(VectorSource(positif_or_negatif$Text))
print(taaruf_corpus)
inspect(taaruf_corpus)
dtm_tweets <- DocumentTermMatrix(VCorpus(VectorSource(datalexicon$Text)))
inspect(dtm_tweets)
dtm_tweets_latih <- dtm_tweets[1:3587, ]
label_sentimen_latih <- datalexicon[1:3587, ]$Summary
konversi_jumlah <- function(x){
x <- ifelse(x > 0, "Ada", "TAda")
}
sentimen_latih <- apply(dtm_tweets_latih,
MARGIN = 2, konversi_jumlah)
#melatih data training
library(e1071)
pengklas_sentimen <-naiveBayes(sentimen_latih, label_sentimen_latih)
pengklas_sentimen$apriori
prediksi_sentimen <- predict(pengklas_sentimen, sentimen_latih)
table(prediksi_sentimen)
#hasil dalam bentuk tabel
library(gmodels)
CrossTable(prediksi_sentimen, label_sentimen_latih,
prop.chisq = F,prop.t = F,
dnn = c('terprediksi' , 'manual'))
#mengetahui akurasi perhitungan menggunakan confusion matrix
library(caret)
conf.mat <- confusionMatrix(prediksi_sentimen, label_sentimen_latih )
table(prediksi_sentimen)
conf.mat
View('prediksi_sentimen')
View('table_finalfix.csv')
dtm_tweets <- DocumentTermMatrix(VCorpus(VectorSource(datalexicon$Text)))
inspect(dtm_tweets)
dtm_tweets_latih <- dtm_tweets[1:3587, ]
label_sentimen_latih <- datalexicon[1:3587, ]$Summary
konversi_jumlah <- function(x){
x <- ifelse(x > 0, "Ada", "TAda")
}
sentimen_latih <- apply(dtm_tweets_latih,
MARGIN = 2, konversi_jumlah)
pengklas_sentimen <-naiveBayes(sentimen_latih, label_sentimen_latih)
pengklas_sentimen$apriori
pengklas_sentimen$tables[1]
prediksi_sentimen <- predict(pengklas_sentimen, sentimen_latih)
table(prediksi_sentimen)
#hasil dalam bentuk tabel
library(gmodels)
CrossTable(prediksi_sentimen, label_sentimen_latih,
prop.chisq = F,prop.t = F,
dnn = c('terprediksi' , 'manual'))
#mengetahui akurasi perhitungan menggunakan confusion matrix
library(caret)
conf.mat <- confusionMatrix(prediksi_sentimen, label_sentimen_latih )
table(prediksi_sentimen)
conf.mat
View('prediksi_sentimen')
View('table_finalfix2.csv')
dtm_tweets <- DocumentTermMatrix(VCorpus(VectorSource(datalexicon$Text)))
inspect(dtm_tweets)
dtm_tweets_uji <- dtm_tweets[3588:5124, ]
label_sentimen_uji <- datalexicon[3588:5124, ]$Summary
konversi_jumlah <- function(x){
x <- ifelse(x > 0, "Ada", "TAda")
}
sentimen_uji <- apply(dtm_tweets_uji,
MARGIN = 2, konversi_jumlah)
pengklas_sentimen <-naiveBayes(sentimen_uji, label_sentimen_uji)
pengklas_sentimen$apriori
pengklas_sentimen$tables[1]
prediksi_sentimen <- predict(pengklas_sentimen, sentimen_uji)
table(prediksi_sentimen)
shiny::runApp('~/KUUUUUULIAAAHHHH/Skripsi/Program/sentimentaaruf')
CrossTable(prediksi_sentimen, label_sentimen_uji,
prop.chisq = F,prop.t = F,
dnn = c('terprediksi' , 'manual'))
conf.mat <- confusionMatrix(prediksi_sentimen, label_sentimen_uji )
table(prediksi_sentimen)
conf.mat
negatif_cloud <- which(positif_or_negatif$Summary =="Negative")
positif_cloud <- which(positif_or_negatif$Summary =="Positive")
library(wordcloud)
library(RColorBrewer)
wordcloud(words = taaruf_corpus[negatif_cloud], min.freq = 3, max.words = 300, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8,"Dark2"), main="Wordcloud Negatif")
wordcloud(words = taaruf_corpus[positif_cloud], min.freq = 5, max.words = 300, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8,"Dark2"), main="Wordcloud Positif")
runApp()
runApp()
mytable <- table(label_sentimen_latih)
lbls <- paste(names(mytable), "\n", mytable, sep="")
pie3D(mytable, labels =lbls, radius=0.8,explode=0.3,shade=0.9, theta=0.4, main="Diagram Pie Data Latih")
pie(mytable, labels = lbls, main="Diagram Pie Data Latih")
mytable2 <- table(label_sentimen_uji)
lbls <- paste(names(mytable2), "\n", mytable2, sep="")
pie3D(mytable2, labels =lbls, radius=0.8,explode=0.3,shade=0.9, theta=0.4, main="Diagram Pie Data Uji")
pie(mytable2, labels = lbls, main="Diagram Pie Data Uji")
library(plotrix)
mytable <- table(label_sentimen_latih)
lbls <- paste(names(mytable), "\n", mytable, sep="")
pie3D(mytable, labels =lbls, radius=0.8,explode=0.3,shade=0.9, theta=0.4, main="Diagram Pie Data Latih")
pie(mytable, labels = lbls, main="Diagram Pie Data Latih")
mytable2 <- table(label_sentimen_uji)
lbls <- paste(names(mytable2), "\n", mytable2, sep="")
pie3D(mytable2, labels =lbls, radius=0.8,explode=0.3,shade=0.9, theta=0.4, main="Diagram Pie Data Uji")
pie(mytable2, labels = lbls, main="Diagram Pie Data Uji")
mytable3 <- table(prediksi_sentimen)
lbls <- paste(names(mytable3), "\n", mytable3, sep="")
pie3D(mytable3, labels =lbls, radius=0.8,explode=0.3,shade=0.9, theta=0.4, main="Diagram Pie Hasil Klasifikasi Data Uji")
pie(mytable3, labels = lbls, main="Diagram Pie Hasil Klasifikasi Data Uji")
shiny::runApp()
runApp()
shiny::runApp('~/KUUUUUULIAAAHHHH/Skripsi/Program/sentimentaaruff/BARU')
runApp('~/KUUUUUULIAAAHHHH/Skripsi/Program/sentimentaaruff/BARU')
library(tm)
library(RTextTools)
library(e1071)
library(dplyr)
library(caret)
# Library for parallel processing
# install.packages("doMC", repos="http://R-Forge.R-project.org")
library(doMC)
registerDoMC(cores=detectCores())  # Use all available cores
df<- read.csv(file.choose(), stringsAsFactors = FALSE)
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
df<- read.csv(table_finalfix2.csv, stringsAsFactors = FALSE)
df<- read.csv(table_finalfix, stringsAsFactors = FALSE)
library(tm)
df<- read.csv("table_finalfix2", stringsAsFactors = FALSE)
df<- read.csv(file.choose(), stringsAsFactors = FALSE)
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
corpus <- Corpus(VectorSource(df$text))
# Inspect the corpus
corpus
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus[1:3])
# Use dplyr's  %>% (pipe) utility to do this neatly.
corpus.clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus.clean)
# Inspect the dtm
inspect(dtm[40:50, 10:15])
df<- read.csv(file.choose(), stringsAsFactors = FALSE)
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
corpus <- Corpus(VectorSource(df$text))
# Inspect the corpus
corpus
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus[1:3])
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus)
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus[1:3])
# Use dplyr's  %>% (pipe) utility to do this neatly.
corpus.clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus)
df<- read.csv(file.choose(), stringsAsFactors = FALSE)
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
corpus <- Corpus(VectorSource(df$text))
# Inspect the corpus
corpus
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus[1:3])
# Use dplyr's  %>% (pipe) utility to do this neatly.
corpus.clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
df<- read.csv(file.choose(), stringsAsFactors = FALSE)
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
corpus <- Corpus(VectorSource(df$text))
# Inspect the corpus
corpus
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus)
dtm <- DocumentTermMatrix(corpus.clean)
dtm <- DocumentTermMatrix(corpus)
# Inspect the dtm
inspect(dtm[40:50, 10:15])
df.train <- df[1:1500,]
df.test <- df[1501:2000,]
dtm.train <- dtm[1:1500,]
dtm.test <- dtm[1501:2000,]
glimpse(df)
table(df$class)
set.seed(1)
df <- df[sample(nrow(df)), ]
df <- df[sample(nrow(df)), ]
glimpse(df)
df$class <- as.factor(df$class)
corpus <- Corpus(VectorSource(df$text))
# Inspect the corpus
corpus
## <<VCorpus>>
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 2000
inspect(corpus)
# Use dplyr's  %>% (pipe) utility to do this neatly.
corpus <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus)
# Inspect the dtm
inspect(dtm[40:50, 10:15])
df.train <- df[1:1500,]
df.test <- df[1501:2000,]
dtm.train <- dtm[1:1500,]
dtm.test <- dtm[1501:2000,]
corpus.train <- corpus[1:1500]
corpus.test <- corpus[1501:2000]
dim(dtm.train)
dtm.train <- DocumentTermMatrix(corpus.train)
dim(dtm.train)
dtm.test <- DocumentTermMatrix(corpus.test)
dim(dtm.train)
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
# Apply the convert_count function to get final training and testing DTMs
train <- apply(dtm.train, 2, convert_count)
test <- apply(dtm.test, 2, convert_count)
# Train the classifier
system.time( classifier <- naiveBayes(train, df.train$class, laplace = 1) )
# Use the NB classifier we built to make predictions on the test set.
system.time( pred <- predict(classifier, newdata=test) )
# Create a truth table by tabulating the predicted class labels with the actual class labels
table("Predictions"= pred,  "Actual" = df.test$class )
# Prepare the confusion matrix
conf.mat <- confusionMatrix(pred, df.test$class)
conf.mat
conf.mat$byClass
conf.mat$overall
# Prediction Accuracy
conf.mat$overall['Accuracy']
shiny::runApp()
